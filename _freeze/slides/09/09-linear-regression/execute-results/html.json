{
  "hash": "e03a947543b4a7e46e47814b7ea1a049",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Linear Regression\nsubtitle: Chp 7\nformat: revealjs\nauto-stretch: false\nauthor: \"\"\neditor: \n  markdown: \n    wrap: 72\n---\n\n::: {.cell}\n\n:::\n\n\n## In groups\n\n-   Discuss Homework: \\S 7.5 #1, 3, 7, 9, 19\n\n## `crickets` {visibility=\"hidden\"}\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncrickets <- read_csv(\"crickets.csv\")\n\nggplot(data = crickets, aes(x = temp_F, y = chirps_in_15s)) +\n  geom_point() +\n  labs(\n    x = \"Temperature\", \n    y = \"Chirps per 15s\", \n    title = \"Cricket Chirps and Temperature\",\n  )\n```\n:::\n\n\n------------------------------------------------------------------------\n\n## Cricket Chirps and Temperature\n\nDo cricket chirp rates and air temperature seem to be associated?\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](09-linear-regression_files/figure-revealjs/unnamed-chunk-4-1.png){width=85%}\n:::\n:::\n\n\n## Linear Regression\n\nBest fit line\n\nLinear model\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](09-linear-regression_files/figure-revealjs/unnamed-chunk-5-1.png){width=85%}\n:::\n:::\n\n\n## Simple regression model and notation {.smaller visibility=\"hidden\"}\n\n$$\ny = \\beta_0 + \\beta_1 x + \\epsilon\n$$\n\n::: incremental\n-   $x$: the **predictor**. Also commonly referred to as *explanatory*\n    or *independent* variable\"\n\n-   $y$: the **response** variable. Also called the *outcome* or\n    *dependent variable*. In prediction problems, this is what we are\n    interested in predicting.\n\n-   $\\beta_0$, $\\beta_1$ are constants or **coefficients**. They are\n    **population parameters**. $\\beta_0$ has another special name, \"the\n    intercept\".\n\n-   $\\epsilon$: the **error**. This quantity represents observational\n    error, i.e. the difference between our observation and the true\n    population-level expected value: $\\beta_0 + \\beta_1 x$.\n:::\n\n. . .\n\nEffectively this model says our data $y$ is linearly related to $x$ (but\nnot exactly linear)\n\n## linear_reg {visibility=\"hidden\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n model_fit <- linear_reg() |>\n      fit(chirps_in_15s ~ temp_F, data = crickets)\n \ntidy(model_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)   -0.372    3.23      -0.115 0.910   \n2 temp_F         0.212    0.0402     5.27  0.000151\n```\n\n\n:::\n:::\n\n\n## Finding the regression line\n\nRecall -- a line has the equation $$ y = m x + b$$ where $m$ is the\n**slope** and $b$ is the **intercept**.\n\n\\\n\n-   $x$ is the **predictor** or **explanatory** or **independent**\n    variable\n\n-   $y$ is the **response** or **outcome** or **dependent** variable. In\n    prediction problems, this is what we are interested in predicting.\n\n## Residuals\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](09-linear-regression_files/figure-revealjs/unnamed-chunk-7-1.png){width=960}\n:::\n:::\n\n\n## **least squares** regression line\n\n$$ \\hat{y} = b_0 + b_1 \\cdot \\hat{x} $$\n\n-   Minimizes (sum of squared) distance between data points and line\n-   *Residuals* balance out above and below line\n-   The point $(\\bar{x}, \\bar{y})$ always lies on line (though it's not\n    necessarily a data point!)\n\n## Correlation coefficient, *r*\n\nAlso called the Pearson Product-Moment Correlation, here's how *r* is\ncalculated:\n\n$$ r = \\frac{1}{n-1}\\sum_{i=1}^n \\frac{ x_i - \\bar{x}}{s_x} \\frac{y_i - \\bar{y}}{s_y}\n$$ We'll have R do this for us!\n\n## Correlation coefficient, *r*\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncrickets |>\n  summarize(N = n(), \n            mean_x = mean(temp_F),\n            sd_x = sd(temp_F),\n            mean_y = mean(chirps_in_15s),\n            sd_y = sd(chirps_in_15s),\n            r = cor(temp_F, chirps_in_15s)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 6\n      N mean_x  sd_x mean_y  sd_y     r\n  <int>  <dbl> <dbl>  <dbl> <dbl> <dbl>\n1    15   80.1  6.72   16.6  1.72 0.825\n```\n\n\n:::\n:::\n\n\n## Finding the regression line\n\n$$ \\hat{y} = b_0 + b_1 \\cdot \\hat{x} $$ First we find the slope:\n$$b_1 = r \\left( \\frac{s_y}{s_x} \\right)$$\n\nIn this formula:\n\n-   $r$ = correlation coefficient\n-   $s_y$ = standard deviation of $y$\n-   $s_x$ = standard deviation of $x$\n\n## Finding the regression line\n\n$$ \\hat{y} = b_0 + b_1 \\cdot \\hat{x} $$ Next we use the fact that\n$(\\bar{x}, \\bar{y})$ is on the line. Plug these values into line\nequation\n\n$$\\bar{y} = b_0 + b_1 \\cdot \\bar{x} $$ Now everything is known except\n$b_0$ so we can solve for that!\n\n$$\nb_0 = \\bar{y} - b_1 \\bar{x}\n$$\n\n## Calculuate!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(chirps_in_15s ~ temp_F, data=crickets)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = chirps_in_15s ~ temp_F, data = crickets)\n\nCoefficients:\n(Intercept)       temp_F  \n    -0.3721       0.2118  \n```\n\n\n:::\n:::\n\n\n## Linear Model\n\n$$\n\\hat{y} = 0.212 \\hat{x} - 0.372\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = crickets, aes(x = temp_F, y = chirps_in_15s)) +\n  geom_point() +\n  geom_abline(slope = 0.212, intercept = -0.372, color=\"blue\")\n```\n\n::: {.cell-output-display}\n![](09-linear-regression_files/figure-revealjs/unnamed-chunk-10-1.png){width=85%}\n:::\n:::\n\n\n## Next Steps\n\n-   What can we do with our linear model (i.e. regression line)?\n-   What is the significance of correlation coefficient $r$?\n",
    "supporting": [
      "09-linear-regression_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}